{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface datasets scikit_learn seaborn spacy tensorflow tf-keras\n",
    "!pip install numpy==1.26.4\n",
    "!pip install --upgrade transformers datasets torch scikit-learn matplotlib seaborn optimum bitsandbytes accelerate peft gdown transformers[torch]\n",
    "# !pip install transformers==4.45.1 datasets torch scikit-learn numpy==1.26.4 matplotlib seaborn optimum bitsandbytes accelerate peft gdown transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import gdown\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import BitsAndBytesConfig\n",
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_huggingface():\n",
    "    try:\n",
    "        user_secrets = UserSecretsClient()\n",
    "        hf_token = user_secrets.get_secret(\"HF LLama3.2 Token\")\n",
    "        huggingface_hub.login(token=hf_token)\n",
    "        print(\"Successfully logged in to Hugging Face\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to log in to Hugging Face: {e}\")\n",
    "        print(\"Ensure HF_TOKEN is set in Kaggle Secrets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(base_path):\n",
    "    levels = ['easy', 'medium', 'hard']\n",
    "    splits = ['train', 'validation']\n",
    "    dataset = {}\n",
    "\n",
    "    for level in levels:\n",
    "        dataset[level] = {}\n",
    "        for split in splits:\n",
    "            split_path = os.path.join(base_path, level, split)\n",
    "            documents = []\n",
    "            for filename in sorted(os.listdir(split_path)):\n",
    "                if filename.startswith('problem-') and filename.endswith('.txt'):\n",
    "                    problem_id = filename.split('.')[0]\n",
    "                    txt_path = os.path.join(split_path, filename)\n",
    "                    json_path = os.path.join(split_path, f'truth-{problem_id}.json')\n",
    "                    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                        sentences = [line.strip() for line in f.readlines() if line.strip()]\n",
    "                    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                        truth = json.load(f)\n",
    "                        changes = truth['changes']\n",
    "                    documents.append((sentences, changes, problem_id))\n",
    "            dataset[level][split] = documents\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_llama_data(documents, tokenizer, max_length=512):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    problem_ids_with_offsets = []\n",
    "    offset = 0\n",
    "    \n",
    "    for sentences, changes, problem_id in documents:\n",
    "        for i in range(len(changes)):\n",
    "            pair_text = sentences[i] + \" [SEP] \" + sentences[i + 1]\n",
    "            texts.append(pair_text)\n",
    "            labels.append(changes[i])\n",
    "            problem_ids_with_offsets.append((problem_id, i, offset + i))\n",
    "        offset += len(changes)\n",
    "    \n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    dataset = Dataset.from_dict({\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': encodings['attention_mask'],\n",
    "        'labels': labels\n",
    "    })\n",
    "    \n",
    "    return dataset, problem_ids_with_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['No Change (0)', 'Change (1)'],\n",
    "                yticklabels=['No Change (0)', 'Change (1)'])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_json(predictions, problem_ids_with_offsets, output_base_path, level, split):\n",
    "    output_dir = os.path.join(output_base_path, level, split)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pred_dict = {}\n",
    "    for pred, (problem_id, idx, offset) in zip(predictions, problem_ids_with_offsets):\n",
    "        if problem_id not in pred_dict:\n",
    "            pred_dict[problem_id] = []\n",
    "        pred_dict[problem_id].append(int(pred))\n",
    "    for problem_id, changes in pred_dict.items():\n",
    "        solution = {\"changes\": changes}\n",
    "        output_path = os.path.join(output_dir, f'solution-{problem_id}.json')\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(solution, f, indent=4)\n",
    "        print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = (logits > 0).astype(int).flatten()\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    return {'accuracy': accuracy, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_llama(train_dataset, val_dataset, val_problem_ids_with_offsets, level, output_base_path, model_name):\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Set padding token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    # Define quantization config (4-bit)\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  # Use 4-bit quantization\n",
    "        bnb_4bit_compute_dtype=torch.float16,  # FP16 for computation\n",
    "        bnb_4bit_use_double_quant=True,  # Double quantization\n",
    "        bnb_4bit_quant_type=\"nf4\"  # Normalized float 4-bit\n",
    "    )\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=1,\n",
    "        problem_type=\"regression\",\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Update model config\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.use_cache = False  # Disable cache for gradient checkpointing\n",
    "    \n",
    "    # Apply LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\"\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # Enable gradient checkpointing\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Compute class weights for imbalanced data\n",
    "    labels = train_dataset['labels']\n",
    "    pos_weight = float((len(labels) - sum(labels)) / sum(labels))\n",
    "    \n",
    "    # Custom Trainer to handle pos_weight in loss\n",
    "    class WeightedBCELossTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            device = logits.device\n",
    "            loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight).to(device))\n",
    "            loss = loss_fn(logits.squeeze(), labels.float())\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    # # Training arguments optimized for Kaggle\n",
    "    # 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\n",
    "    # training_args = TrainingArguments(\n",
    "    #     output_dir=f\"/kaggle/working/results/{level}\",\n",
    "    #     num_train_epochs=3,\n",
    "    #     per_device_train_batch_size=2,\n",
    "    #     per_device_eval_batch_size=2,\n",
    "    #     gradient_accumulation_steps=4,\n",
    "    #     warmup_steps=500,\n",
    "    #     weight_decay=0.01,\n",
    "    #     learning_rate=2e-5,  # Optimized learning rate\n",
    "    #     logging_dir=f\"/kaggle/working/logs/{level}\",\n",
    "    #     logging_steps=10,\n",
    "    #     eval_strategy=\"epoch\",\n",
    "    #     save_strategy=\"epoch\",\n",
    "    #     load_best_model_at_end=True,\n",
    "    #     metric_for_best_model=\"f1\",\n",
    "    #     fp16=True,  # Enable FP16 mixed precision\n",
    "    #     gradient_checkpointing=True,\n",
    "    #     report_to=\"none\",\n",
    "    #     save_total_limit=1,  # Keep only the best checkpoint\n",
    "    #     optim=\"adamw_torch\"  # Explicit optimizer\n",
    "    # )\n",
    "    # Training arguments optimized for Kaggle\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"/kaggle/working/results/{level}\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-5,\n",
    "        logging_dir=f\"/kaggle/working/logs/{level}\",\n",
    "        logging_steps=10,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        gradient_checkpointing=True,\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=1,\n",
    "        optim=\"adamw_torch\"\n",
    "    )\n",
    "    \n",
    "    # Define trainer\n",
    "    trainer = WeightedBCELossTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        # label_names=[\"labels\"]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"\\n{level} Level Metrics:\")\n",
    "    print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}, F1-Score: {eval_results['eval_f1']:.4f}\")\n",
    "    \n",
    "    # Predict\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    pred_labels = (predictions.predictions > 0).astype(int).flatten()\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(val_dataset['labels'], pred_labels, target_names=['No Change (0)', 'Change (1)']))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = plot_confusion_matrix(val_dataset['labels'], pred_labels, f'Confusion Matrix - {level} Level')\n",
    "    \n",
    "    # Save predictions\n",
    "    save_predictions_to_json(pred_labels, val_problem_ids_with_offsets, output_base_path, level, 'validation')\n",
    "    \n",
    "    return model, tokenizer, pred_labels, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../dataset\"\n",
    "print(\"Loading Dataset...\")\n",
    "dataset = load_dataset(dataset_dir)\n",
    "print(\"Loaded Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_path = \"/kaggle/working/outputs-llama3.2\"\n",
    "os.mkdirs(output_base_path, exist_ok=True)\n",
    "# os.makedirs(output_base_path, exist_ok=True)\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_labels = []\n",
    "all_val_pred = []\n",
    "all_cm = None\n",
    "\n",
    "levels = ['easy', 'medium', 'hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in levels:\n",
    "    print(f\"\\nProcessing {level} level...\")\n",
    "    \n",
    "    train_docs = dataset[level]['train']\n",
    "    val_docs = dataset[level]['validation']\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    train_dataset, _ = prepare_llama_data(train_docs, tokenizer, max_length)\n",
    "    val_dataset, val_problem_ids_with_offsets = prepare_llama_data(val_docs, tokenizer, max_length)\n",
    "    \n",
    "    model, tokenizer, val_pred, cm = train_and_evaluate_llama(\n",
    "        train_dataset, val_dataset, val_problem_ids_with_offsets, level, output_base_path, model_name\n",
    "    )\n",
    "    \n",
    "    all_val_labels.extend(val_dataset['labels'])\n",
    "    all_val_pred.extend(val_pred)\n",
    "    if all_cm is None:\n",
    "        all_cm = cm\n",
    "    else:\n",
    "        all_cm += cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCombined Metrics Across All Levels:\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_val_labels, all_val_pred, target_names=['No Change (0)', 'Change (1)']))\n",
    "plot_confusion_matrix(all_val_labels, all_val_pred, 'Combined Confusion Matrix - All Levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"../models\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "print(\"Training and evaluation completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
